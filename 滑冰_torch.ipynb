{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0fb8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0a5d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 2500  #序列长度，最大帧为300，但这里还需要更改\n",
    "input_size = 75       #输入数据特征大小 3（x,y,z）*25（关节数量）\n",
    "hidden_size = 128     #隐藏层数据特征大小,即每个时间步对应的ht的维数\n",
    "num_layers = 2        #隐藏层层数\n",
    "num_classes = 30      #结果类数\n",
    "batch_size = 20     #一个batch大小\n",
    "num_epochs = 100       #epoch数目\n",
    "learning_rate = 0.001  #学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c270452",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feeder(torch.utils.data.Dataset): \n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 label_path,\n",
    "                 window_size=-1,\n",
    "                 debug=False,\n",
    "                 mmap=True):\n",
    "        self.debug = debug\n",
    "        self.data_path = data_path\n",
    "        self.label_path = label_path\n",
    "        self.window_size = window_size\n",
    "        self.load_data(mmap)\n",
    "        \n",
    "    def load_data(self, mmap):\n",
    "        # data: N C V T M\n",
    "\n",
    "        self.label = np.load(label_path)\n",
    "        \n",
    "        self.data = np.load(data_path)\n",
    "\n",
    "        self.N, self.C, self.T, self.V, self.M = self.data.shape\n",
    "\n",
    "    # 获取数据集大小\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    # 用于获取某一个数据的函数\n",
    "    def __getitem__(self, index):\n",
    "        data_numpy = np.array(self.data[index])\n",
    "        label = self.label[index]\n",
    "\n",
    "        return data_numpy, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a331610",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/kongxuwen/Desktop/竞赛/滑冰/train_dataset/train_data.npy'\n",
    "label_path = '/Users/kongxuwen/Desktop/竞赛/滑冰/train_dataset/train_label.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e623875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27, 27, 27, ..., 11, 11, 11])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "973fab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Feeder(data_path,label_path)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc35ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HRNN(nn.Module):\n",
    "    # 实现三层架构，即首先经过两层普通BRNN并经过全连接层融合，最后经过一层LSTM的BRNN，然后用FC表示\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(HRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        #如果要使用反向的传递，则需令bidirectional=True\n",
    "        # batch_first代表传入数据为（batch,seq,feature)的顺序 否则Pytroch所有RNN网络默认输入结构为(seq,batch,feature)\n",
    "        # batch_first = true代表输入X为 batch_size,seq_len,input_size\n",
    "        self.rnn = nn.RNN(int(input_size/5), int(hidden_size/4), num_layers, batch_first=True, bidirectional=True)\n",
    "        self.rnn2 = nn.RNN(hidden_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.lstm = nn.LSTM(int(hidden_size/4*2*2), hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        \n",
    "        #如果使用了反向传递，则需要将hidden_size*2!\n",
    "        self.fc = nn.Linear(hidden_size*2*sequence_length, num_classes)\n",
    "        self.fs1 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.fs2 = nn.Linear(hidden_size*4,hidden_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 输入：\n",
    "        # X为batch_size*seq_len*input_size(batch_first=true时)\n",
    "        \n",
    "        # 输出：\n",
    "        # 输出为out,(hn,cn)\n",
    "        # out(seq_len, batch_size, num_directions*hidden_size) 即为[h1,h2,...,hseq_len]\n",
    "        # 即out = torch.Size([1000, 28, 128])\n",
    "        # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        '''\n",
    "        in2_p1 = torch.zeros(400,28,128)\n",
    "        in2_p2 = torch.zeros(400,28,128)\n",
    "        in2_p3 = torch.zeros(400,28,128)\n",
    "        in2_p4 = torch.zeros(400,28,128)\n",
    "        \n",
    "        in3_p1 = torch.zeros(800,28,128)\n",
    "        in3_p2 = torch.zeros(800,28,128)\n",
    "        \n",
    "        in4_p1 = torch.zeros(1600,28,128)\n",
    "        '''\n",
    "        # layer1:即分成五个部分利用rnn进行分别建模 75/5\n",
    "        # step1:将五个部分分别经过rnn层\n",
    "        (x_p1,x_p2,x_p3,x_p4,x_p5) = torch.chunk(x, 5, dim = 2)\n",
    "        out1_p1,_ = self.rnn(x_p1)#(20,2500,64)\n",
    "        out1_p2,_ = self.rnn(x_p2)\n",
    "        out1_p3,_ = self.rnn(x_p3)\n",
    "        out1_p4,_ = self.rnn(x_p4)\n",
    "        out1_p5,_ = self.rnn(x_p5)\n",
    "        # 经过第一个RNN得到的是五个子部分的表示\n",
    "        print(out1_p1.shape)\n",
    "        \n",
    "        # step2:利用全连接层进行特征融合\n",
    "        # 先进行特征拼接\n",
    "        temp2_p1 = torch.cat((out1_p1,out1_p2),2) #(20,2500,128/4*2*2),第一个2为双向乘的，第二个2为两个并在一起乘的\n",
    "        temp2_p2 = torch.cat((out1_p1,out1_p3),2)\n",
    "        temp2_p3 = torch.cat((out1_p1,out1_p4),2)\n",
    "        temp2_p4 = torch.cat((out1_p1,out1_p5),2)\n",
    "        print(temp2_p1.shape)\n",
    "        # 再进行特征融合\n",
    "#         seqs = temp2_p1.size(1)\n",
    "        in2_p1 = F.relu(self.fs1(temp2_p1))\n",
    "#         for seq in range(seqs):\n",
    "#             temp = torch.squeeze(temp2_p1[:,seq,:],dim=1) #删除这个维度\n",
    "#             in2_p1_i = F.relu(self.fs1(temp))\n",
    "#             in2_p1.append(in2_p1_i)\n",
    "#         in2_p1 = torch.stack(in2_p1,dim = 1)\n",
    "        in2_p2 = F.relu(self.fs1(temp2_p2))\n",
    "#         for seq in range(seqs):\n",
    "#             temp = torch.squeeze(temp2_p2[:,seq,:],dim=1) #删除这个维度\n",
    "#             in2_p2_i = F.relu(self.fs1(temp))\n",
    "#             in2_p2.append(in2_p2_i)\n",
    "#         in2_p2 = torch.stack(in2_p2,dim = 1)\n",
    "        in2_p3 = F.relu(self.fs1(temp2_p3))\n",
    "#         for seq in range(seqs):\n",
    "#             temp = torch.squeeze(temp2_p3[:,seq,:],dim=1) #删除这个维度\n",
    "#             in2_p3_i = F.relu(self.fs1(temp))\n",
    "#             in2_p3.append(in2_p3_i)\n",
    "#         in2_p3 = torch.stack(in2_p3,dim = 1)\n",
    "        in2_p4 = F.relu(self.fs1(temp2_p4))\n",
    "#         for seq in range(seqs):\n",
    "#             temp = torch.squeeze(temp2_p4[:,seq,:],dim=1) #删除这个维度\n",
    "#             in2_p4_i = F.relu(self.fs1(temp))\n",
    "#             in2_p4.append(in2_p4_i)\n",
    "#         in2_p4 = torch.stack(in2_p4,dim = 1)\n",
    "        print(in2_p1.shape)\n",
    "        \n",
    "        # layer2:用4个部分进行输入，得到结果经过融合层变成两部分\n",
    "        # step1:四个部分分别经过第二个rnn层\n",
    "        out2_p1,_ = self.rnn2(in2_p1)#(20,2500,256)\n",
    "        out2_p2,_ = self.rnn2(in2_p2)\n",
    "        out2_p3,_ = self.rnn2(in2_p3)\n",
    "        out2_p4,_ = self.rnn2(in2_p4)\n",
    "        print(out2_p1.shape)\n",
    "        # step2:利用全连接层进行特征融合\n",
    "        temp3_p1 = torch.cat((out2_p1,out2_p2),2)#(20,2500,512)\n",
    "        temp3_p2 = torch.cat((out2_p3,out2_p4),2)\n",
    "        print(temp3_p1.shape)\n",
    "        seqs = temp3_p1.size(1)\n",
    "        in3_p1 = F.relu(self.fs2(temp3_p1))\n",
    "#         for seq in range(seqs):\n",
    "#             temp = torch.squeeze(temp3_p1[:,seq,:],dim=1) #删除这个维度\n",
    "#             in3_p1_i = F.relu(self.fs2(temp))\n",
    "#             in3_p1.append(in3_p1_i)\n",
    "#         in3_p1 = torch.stack(in3_p1,dim = 1)\n",
    "        \n",
    "        in3_p2 = F.relu(self.fs2(temp3_p2))\n",
    "#         for seq in range(seqs):\n",
    "#             temp = torch.squeeze(temp3_p2[:,seq,:],dim=1) #删除这个维度\n",
    "#             in3_p2_i = F.relu(self.fs2(temp))\n",
    "#             in3_p2.append(in3_p2_i)\n",
    "#         in3_p2 = torch.stack(in3_p2,dim = 1)\n",
    "        print(in3_p1.shape)\n",
    "        \n",
    "        # layer3:将两个部分的结果再经过rnn层最终得到一个部分的结果\n",
    "        # step1:将两个部分分别经过rnn\n",
    "        out3_p1,_ = self.rnn2(in3_p1)#(,,256)\n",
    "        out3_p2,_ = self.rnn2(in3_p2)\n",
    "        print(out3_p1.shape)\n",
    "        # step2.利用全连接层进行特征融合\n",
    "        temp4_p1 = torch.cat((out3_p1,out3_p2),2)\n",
    "        in4_p1 = F.relu(self.fs2(temp4_p1))\n",
    "#         for seq in range(seqs):\n",
    "#             temp = torch.squeeze(temp4_p1[:,seq,:],dim=1) #删除这个维度\n",
    "#             in4_p1_i = F.relu(self.fs2(temp))\n",
    "#             in4_p1.append(in4_p1_i)\n",
    "#         in4_p1 = torch.stack(in4_p1,1)\n",
    "        \n",
    "        # layer3:整体作为输入经过lstm层得到输出\n",
    "        out4,_ = self.lstm(in4_p1)\n",
    "        #print(out4.shape) torch.Size([1000, 300, 128])\n",
    "        # 代表仅取最后一个时间步的隐状态表示作为全连接层的输入(这显然是不合理的，因为有很多都没有到最后一帧)\n",
    "        #out = self.fc(out4[:, -1, :])\n",
    "        # 尝试一：将向量展平（但这样会存在很多0）\n",
    "        out = self.fc(out4.reshape(out4.size(0),hidden_size*2*sequence_length))\n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91740ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87c5bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step6.模型使用以及损失函数、优化函数使用\n",
    "model = HRNN(input_size, hidden_size, num_layers, num_classes)\n",
    "model.train()\n",
    "# 使用交叉熵损失函数作为目标函数\n",
    "# 使用Adam作为优化函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910646b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(3.4019, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(15.6163, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(28.8647, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(12.6137, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(50.8144, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(25.7781, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(17.0905, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(10.9662, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(15.0837, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(9.6698, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(5.0715, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(7.9526, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(12.3139, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(9.3288, grad_fn=<NllLossBackward0>)\n",
      "done\n",
      "torch.Size([20, 2500, 64])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "torch.Size([20, 2500, 512])\n",
      "torch.Size([20, 2500, 128])\n",
      "torch.Size([20, 2500, 256])\n",
      "tensor(8.6587, grad_fn=<NllLossBackward0>)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    since = time.time()\n",
    "    for batch_x,batch_y in train_loader:\n",
    "        # 暂时只取了第一个身体\n",
    "        batch_x = batch_x[:,:,:,:,0].view(-1,sequence_length,input_size)\n",
    "\n",
    "        batch_x,batch_y = batch_x,batch_y\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logit = model(batch_x)\n",
    "        \n",
    "        loss = criterion(logit,batch_y)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        print('done')\n",
    "        optimizer.step()\n",
    "        \n",
    "    now = time.time()\n",
    "    print('[%d/%d epoch,%.0f secends] loss:%.1e'%(epoch+1,num_epochs,now-since,loss))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kxw] *",
   "language": "python",
   "name": "conda-env-kxw-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
